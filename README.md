# Data Processing and Pipeline from Azure Blob Storage to Mysql using Databricks
In this Project i have taken a random datasets from google and kaggle as well and first stored in the Azure Blob Storage
and then fetch this data into the mount of the databricks and read the data using pyspark code and perform the processing and 
filtering on the datasets. After processing by using the credentials and further making changes in the pyspark code, write or 
stores this datasets in the table format in the Mysql Database which was created in AWS RDS [Mysql]
<img width="875" alt="Project2" src="https://github.com/Deva1717/Data-Pipeline-and-Processing-Using-Databricks/assets/137135341/064645aa-072e-417e-ab1e-795f54292554">

